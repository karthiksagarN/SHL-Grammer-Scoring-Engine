{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SHL Grammar Scoring Engine (Research-Grade)\n",
                "\n",
                "## 1. Introduction & Problem Statement\n",
                "\n",
                "This notebook implements an end-to-end Grammar Scoring Engine for spoken audio samples. The goal is to predict a continuous grammar score (0-5) based on audio input. This is a regression problem.\n",
                "\n",
                "### Methodology\n",
                "To achieve a high-performance and \"research-grade\" solution, we employ a multi-modal feature extraction strategy:\n",
                "1.  **Acoustic Features (Wav2Vec2)**: We use a pre-trained `Wav2Vec2` model to extract rich contextual representations from the raw audio waveform. These embeddings capture fluency, prosody, and hesitation patterns.\n",
                "2.  **Linguistic Features (ASR - Whisper)**: We use OpenAI's `Whisper` model to transcribe the speech into text. From this text, we derive linguistic proxies such as word count and speech rate.\n",
                "3.  **Regression Modeling**: We fuse these features and train ensemble regression models (**Random Forest** and **XGBoost**) to predict the grammar score.\n",
                "\n",
                "This approach moves beyond simple signal processing by leveraging state-of-the-art self-supervised speech models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install necessary packages (if not already installed)\n",
                "# !pip install librosa torchaudio transformers soundfile scikit-learn matplotlib seaborn openai-whisper xgboost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/karthiksagar/anaconda3/envs/shl-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cpu\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import librosa\n",
                "import torch\n",
                "import torchaudio\n",
                "import whisper\n",
                "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
                "from sklearn.model_selection import train_test_split, KFold\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from scipy.stats import pearsonr\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from xgboost import XGBRegressor\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "\n",
                "# Settings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "pd.set_option('display.float_format', '{:.4f}'.format)\n",
                "SEED = 42\n",
                "np.random.seed(SEED)\n",
                "torch.manual_seed(SEED)\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train samples: 409\n",
                        "Test samples: 197\n",
                        "Sample path check: ./dataset/audios/train/audio_173.wav -> Exists: True\n"
                    ]
                }
            ],
            "source": [
                "DATA_DIR = \"./dataset\"\n",
                "TRAIN_CSV = os.path.join(DATA_DIR, \"csvs\", \"train.csv\")\n",
                "TEST_CSV  = os.path.join(DATA_DIR, \"csvs\", \"test.csv\")\n",
                "TRAIN_AUDIO_DIR = os.path.join(DATA_DIR, \"audios\", \"train\")\n",
                "TEST_AUDIO_DIR  = os.path.join(DATA_DIR, \"audios\", \"test\")\n",
                "\n",
                "# Load CSVs\n",
                "train_df = pd.read_csv(TRAIN_CSV)\n",
                "test_df = pd.read_csv(TEST_CSV)\n",
                "\n",
                "# Correct filename paths (Append .wav if missing)\n",
                "def get_audio_path(filename, base_dir):\n",
                "    if not filename.endswith('.wav'):\n",
                "        filename += '.wav'\n",
                "    return os.path.join(base_dir, filename)\n",
                "\n",
                "# Validate paths\n",
                "print(f\"Train samples: {len(train_df)}\")\n",
                "print(f\"Test samples: {len(test_df)}\")\n",
                "\n",
                "# Example check\n",
                "sample_path = get_audio_path(train_df.iloc[0]['filename'], TRAIN_AUDIO_DIR)\n",
                "print(f\"Sample path check: {sample_path} -> Exists: {os.path.exists(sample_path)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Extraction Pipeline\n",
                "\n",
                "We extract two types of features:\n",
                "1.  **Wav2Vec2 Embeddings**: `facebook/wav2vec2-base` model. We extract the last hidden state and pool it per file (Mean + Std).\n",
                "2.  **Whisper ASR Features**: `openai/whisper-tiny` model. We transcribe text and compute `word_count`, `speech_rate`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading Wav2Vec2 model...\n",
                        "Loading Whisper model...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|█████████████████████████████████████| 72.1M/72.1M [00:05<00:00, 12.8MiB/s]\n"
                    ]
                }
            ],
            "source": [
                "# Load Models\n",
                "print(\"Loading Wav2Vec2 model...\")\n",
                "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
                "w2v_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\").to(device)\n",
                "w2v_model.eval()\n",
                "\n",
                "print(\"Loading Whisper model...\")\n",
                "# using 'tiny' for speed, can use 'base' or 'small' for better accuracy\n",
                "whisper_model = whisper.load_model(\"tiny\", device=device) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_features(audio_path):\n",
                "    if not os.path.exists(audio_path):\n",
                "        # Handle missing file gracefully (return zeros)\n",
                "        return np.zeros(768*2), 0, 0\n",
                "        \n",
                "    # 1. Load Audio\n",
                "    # Wav2Vec2 expects 16kHz\n",
                "    waveform, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
                "    duration = len(waveform) / sr\n",
                "    \n",
                "    # 2. Wav2Vec2 Embeddings\n",
                "    inputs = processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True).to(device)\n",
                "    with torch.no_grad():\n",
                "        outputs = w2v_model(**inputs)\n",
                "        # Shape: (1, Sequence_Length, 768)\n",
                "        hidden_states = outputs.last_hidden_state\n",
                "    \n",
                "    # Pooling: Mean & Std over time dimension\n",
                "    mean_pool = torch.mean(hidden_states, dim=1).cpu().squeeze().numpy()\n",
                "    std_pool = torch.std(hidden_states, dim=1).cpu().squeeze().numpy()\n",
                "    w2v_features = np.concatenate([mean_pool, std_pool]) # 768 + 768 = 1536 dim\n",
                "    \n",
                "    # 3. Whisper Transcription (ASR)\n",
                "    # Whisper handles its own loading usually, but we can pass path\n",
                "    text = \"\"\n",
                "    try:\n",
                "        result = whisper_model.transcribe(audio_path)\n",
                "        text = result['text'].strip()\n",
                "    except Exception as e:\n",
                "        print(f\"ASR Error on {audio_path}: {e}\")\n",
                "    \n",
                "    # 4. Linguistic Features (Simple proxies)\n",
                "    word_count = len(text.split())\n",
                "    speech_rate = word_count / duration if duration > 0 else 0\n",
                "    \n",
                "    return w2v_features, word_count, speech_rate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Feature Extraction Loop (Train Data)\n",
                "This may take a few minutes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing Training Data...\n",
                        "Processed 0/409\n",
                        "Processed 50/409\n",
                        "Processed 100/409\n",
                        "Processed 150/409\n",
                        "Processed 200/409\n",
                        "Processed 250/409\n",
                        "Processed 300/409\n",
                        "Processed 350/409\n",
                        "Processed 400/409\n",
                        "Final Feature Matrix Shape: (409, 1538)\n"
                    ]
                }
            ],
            "source": [
                "X_w2v = []\n",
                "X_linguistic = []\n",
                "y = []\n",
                "valid_indices = []\n",
                "\n",
                "print(\"Processing Training Data...\")\n",
                "for idx, row in train_df.iterrows():\n",
                "    path = get_audio_path(row['filename'], TRAIN_AUDIO_DIR)\n",
                "    if os.path.exists(path):\n",
                "        w2v_feat, wc, sr = extract_features(path)\n",
                "        X_w2v.append(w2v_feat)\n",
                "        X_linguistic.append([wc, sr])\n",
                "        y.append(row['label'])\n",
                "        valid_indices.append(idx)\n",
                "        if idx % 50 == 0:\n",
                "            print(f\"Processed {idx}/{len(train_df)}\")\n",
                "    else:\n",
                "        print(f\"Missing file: {path}\")\n",
                "\n",
                "X_w2v = np.array(X_w2v)\n",
                "X_linguistic = np.array(X_linguistic)\n",
                "# Normalize linguistic features\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "scaler_ling = StandardScaler()\n",
                "X_linguistic = scaler_ling.fit_transform(X_linguistic)\n",
                "\n",
                "# Concatenate all features\n",
                "X = np.hstack([X_w2v, X_linguistic])\n",
                "y = np.array(y)\n",
                "\n",
                "print(f\"Final Feature Matrix Shape: {X.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/Val Split\n",
                "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Modeling & Training\n",
                "\n",
                "We evaluate **Random Forest** and **XGBoost**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model 1: Random Forest\n",
                "rf = RandomForestRegressor(n_estimators=300, max_depth=None, random_state=SEED, n_jobs=-1)\n",
                "rf.fit(X_train, y_train)\n",
                "\n",
                "# Model 2: XGBoost\n",
                "xgb = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=6, random_state=SEED, n_jobs=-1)\n",
                "xgb.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(model, name, X_tr, y_tr, X_v, y_v):\n",
                "    # Train Metrics\n",
                "    tr_preds = model.predict(X_tr)\n",
                "    tr_rmse = mean_squared_error(y_tr, tr_preds, squared=False)\n",
                "    \n",
                "    # Val Metrics\n",
                "    val_preds = model.predict(X_v)\n",
                "    val_rmse = mean_squared_error(y_v, val_preds, squared=False)\n",
                "    pearson_corr, _ = pearsonr(y_v, val_preds)\n",
                "    \n",
                "    print(f\"--- {name} ---\")\n",
                "    print(f\"Train RMSE: {tr_rmse:.4f}\")\n",
                "    print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
                "    print(f\"Pearson Correlation: {pearson_corr:.4f}\")\n",
                "    return val_preds\n",
                "\n",
                "print(\"EVALUATION RESULTS:\")\n",
                "rf_preds = evaluate_model(rf, \"Random Forest\", X_train, y_train, X_val, y_val)\n",
                "xgb_preds = evaluate_model(xgb, \"XGBoost\", X_train, y_train, X_val, y_val)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizations\n",
                "Comparing predicted vs true scores for the validation set (XGBoost)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(15, 5))\n",
                "\n",
                "# Scatter Plot\n",
                "plt.subplot(1, 3, 1)\n",
                "sns.scatterplot(x=y_val, y=xgb_preds, alpha=0.6)\n",
                "plt.plot([0, 5], [0, 5], '--r', lw=2) # Identity line\n",
                "plt.xlabel(\"True Grammar Score\")\n",
                "plt.ylabel(\"Predicted Grammar Score\")\n",
                "plt.title(\"XGBoost: True vs Predicted\")\n",
                "\n",
                "# Residual Plot\n",
                "residuals = y_val - xgb_preds\n",
                "plt.subplot(1, 3, 2)\n",
                "sns.histplot(residuals, kde=True, bins=20)\n",
                "plt.title(\"Error Distribution (Residuals)\")\n",
                "plt.xlabel(\"Residual (True - Pred)\")\n",
                "\n",
                "# Feature Importance (Top 10)\n",
                "plt.subplot(1, 3, 3)\n",
                "# Get feature importance\n",
                "importances = xgb.feature_importances_\n",
                "# We have 768 (mean) + 768 (std) + 2 (ling) = 1538 features\n",
                "# It's hard to name all w2v features, so we just plot top indices\n",
                "indices = np.argsort(importances)[::-1][:10]\n",
                "plt.title(\"Top 10 Feature Importances\")\n",
                "plt.bar(range(10), importances[indices])\n",
                "plt.xticks(range(10), indices, rotation=45)\n",
                "plt.xlabel(\"Feature Index\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Test Inference & Submission\n",
                "We will use the **XGBoost** model for final inference as it typically performs better."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_test_w2v = []\n",
                "X_test_ling = []\n",
                "test_filenames = []\n",
                "\n",
                "print(\"Processing Test Data...\")\n",
                "for idx, row in test_df.iterrows():\n",
                "    fname = row['filename']\n",
                "    path = get_audio_path(fname, TEST_AUDIO_DIR)\n",
                "    \n",
                "    if os.path.exists(path):\n",
                "        w2v_feat, wc, sr = extract_features(path)\n",
                "        \n",
                "        X_test_w2v.append(w2v_feat)\n",
                "        X_test_ling.append([wc, sr])\n",
                "        test_filenames.append(fname)\n",
                "        \n",
                "        if idx % 50 == 0:\n",
                "            print(f\"Processed {idx}/{len(test_df)}\")\n",
                "    else:\n",
                "        print(f\"Missing test file: {path}\")\n",
                "        # Impute with mean if needed, but for now append zeros to match shape\n",
                "        X_test_w2v.append(np.zeros(768*2))\n",
                "        X_test_ling.append([0, 0])\n",
                "        test_filenames.append(fname)\n",
                "\n",
                "X_test_w2v = np.array(X_test_w2v)\n",
                "X_test_ling = np.array(X_test_ling)\n",
                "\n",
                "# Scale using training scaler\n",
                "X_test_ling = scaler_ling.transform(X_test_ling)\n",
                "\n",
                "# Combine\n",
                "X_test = np.hstack([X_test_w2v, X_test_ling])\n",
                "\n",
                "# Predict\n",
                "test_preds = xgb.predict(X_test)\n",
                "\n",
                "# Clip predictions to 0-5 range (sanity check)\n",
                "test_preds = np.clip(test_preds, 0, 5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Submission DataFrame\n",
                "submission = pd.DataFrame({\n",
                "    'filename': test_filenames,\n",
                "    'label': test_preds\n",
                "})\n",
                "\n",
                "submission.to_csv(\"submission.csv\", index=False)\n",
                "print(\"Saved submission.csv successfully!\")\n",
                "submission.head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "shl-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
